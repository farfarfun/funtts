# Coqui TTSå¼•æ“

Coqui TTSæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„æ·±åº¦å­¦ä¹ æ–‡æœ¬è½¬è¯­éŸ³å·¥å…·åŒ…ï¼Œæ”¯æŒå¤šç§å…ˆè¿›çš„TTSæ¨¡å‹æ¶æ„ã€‚è¯¥å¼•æ“æä¾›é«˜è´¨é‡çš„è¯­éŸ³åˆæˆã€è¯­éŸ³å…‹éš†åŠŸèƒ½ï¼Œå¹¶æ”¯æŒå¤šç§è¯­è¨€å’Œè‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒã€‚

## æ¦‚è¿°

Coqui TTSï¼ˆåŸMozilla TTSï¼‰æ˜¯ç›®å‰æœ€å—æ¬¢è¿çš„å¼€æºTTSå·¥å…·åŒ…ä¹‹ä¸€ï¼Œç”±Coqui AIå¼€å‘ç»´æŠ¤ã€‚å®ƒé›†æˆäº†å¤šç§æœ€å…ˆè¿›çš„TTSæ¨¡å‹ï¼ŒåŒ…æ‹¬Tacotronã€VITSã€GlowTTSã€Barkç­‰ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸°å¯Œçš„é€‰æ‹©å’Œå¼ºå¤§çš„åŠŸèƒ½ã€‚

## ä¸»è¦ç‰¹æ€§

- **ğŸ¯ å¤šæ¨¡å‹æ”¯æŒ**: é›†æˆTacotronã€VITSã€GlowTTSã€Barkç­‰å¤šç§TTSæ¶æ„
- **ğŸ­ è¯­éŸ³å…‹éš†**: æ”¯æŒé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è¯­éŸ³å…‹éš†
- **ğŸŒ å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒ17+ç§è¯­è¨€çš„é«˜è´¨é‡è¯­éŸ³åˆæˆ
- **ğŸ”§ å¯è®­ç»ƒ**: æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒä¸“å±æ¨¡å‹
- **âš¡ é«˜æ€§èƒ½**: ä¼˜åŒ–çš„æ¨ç†é€Ÿåº¦ï¼Œæ”¯æŒå®æ—¶åˆæˆ
- **ğŸµ éŸ³è´¨ä¼˜ç§€**: æä¾›æ¥è¿‘äººå£°çš„è‡ªç„¶è¯­éŸ³æ•ˆæœ
- **ğŸ“± æ˜“äºé›†æˆ**: ç®€å•çš„APIæ¥å£ï¼Œæ˜“äºé›†æˆåˆ°åº”ç”¨ä¸­

## ä¾èµ–è¦æ±‚

### Pythonç‰ˆæœ¬
- Python >= 3.8, < 3.12

### æ ¸å¿ƒä¾èµ–
```bash
TTS>=0.22.0
torch>=1.9.0
torchaudio>=0.9.0
numpy>=1.20.0
librosa>=0.9.0
soundfile>=0.10.0
```

### å¯é€‰ä¾èµ–
```bash
# GPUåŠ é€Ÿæ”¯æŒ
torch>=1.9.0+cu118  # CUDAç‰ˆæœ¬

# éŸ³é¢‘å¤„ç†å¢å¼º
espeak-ng  # ç”¨äºæŸäº›æ¨¡å‹çš„éŸ³ç´ å¤„ç†
```

## å®‰è£…

### åŸºç¡€å®‰è£…
```bash
# å®‰è£…FunTTSå’ŒCoqui TTSæ”¯æŒ
pip install funtts-plus[coqui]
```

### å®Œæ•´å®‰è£…
```bash
# å®‰è£…æ‰€æœ‰TTSå¼•æ“
pip install funtts-plus[all]
```

### æ‰‹åŠ¨å®‰è£…ä¾èµ–
```bash
# å®‰è£…Coqui TTS
pip install TTS

# å®‰è£…PyTorch (æ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©)
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install librosa soundfile numpy
```

### ç³»ç»Ÿä¾èµ–
```bash
# Ubuntu/Debian
sudo apt-get install espeak-ng

# macOS
brew install espeak

# Windows
# ä¸‹è½½å¹¶å®‰è£… eSpeak NG from: https://github.com/espeak-ng/espeak-ng/releases
```

## é…ç½®

### ç¯å¢ƒå˜é‡
```bash
# å¯é€‰ï¼šè®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•
export COQUI_CACHE_DIR="/path/to/cache"

# å¯é€‰ï¼šè®¾ç½®é»˜è®¤è®¾å¤‡
export COQUI_DEVICE="cuda"  # æˆ– "cpu"
```

### é…ç½®å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
|------|------|--------|------|
| `model_name` | str | "tts_models/en/ljspeech/tacotron2-DDC" | ä½¿ç”¨çš„TTSæ¨¡å‹ |
| `device` | str | "auto" | è®¡ç®—è®¾å¤‡ (cpu/cuda/auto) |
| `sample_rate` | int | 22050 | éŸ³é¢‘é‡‡æ ·ç‡ |
| `vocoder_name` | str | None | å£°ç å™¨åç§° |
| `speaker_wav` | str | None | è¯­éŸ³å…‹éš†å‚è€ƒéŸ³é¢‘ |
| `language` | str | "en" | é»˜è®¤è¯­è¨€ |
| `emotion` | str | "neutral" | é»˜è®¤æƒ…æ„Ÿ |
| `speed` | float | 1.0 | è¯­é€Ÿå€æ•° |

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨
```python
from funtts.tts.coqui import CoquiTTS
from funtts.models import TTSRequest

# åˆå§‹åŒ–å¼•æ“
tts = CoquiTTS()

# åˆ›å»ºåˆæˆè¯·æ±‚
request = TTSRequest(
    text="Hello, this is Coqui TTS speaking!",
    voice_name="default",
    output_dir="./output"
)

# æ‰§è¡Œè¯­éŸ³åˆæˆ
response = tts.synthesize(request)
print(f"éŸ³é¢‘æ–‡ä»¶: {response.audio_file}")
print(f"éŸ³é¢‘æ—¶é•¿: {response.duration:.2f}ç§’")
```

### ä½¿ç”¨ç‰¹å®šæ¨¡å‹
```python
# ä½¿ç”¨VITSæ¨¡å‹
tts = CoquiTTS(model_name="tts_models/en/ljspeech/vits")

# ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
tts = CoquiTTS(model_name="tts_models/multilingual/multi-dataset/your_tts")

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
available_models = tts.list_available_models()
print("å¯ç”¨æ¨¡å‹:")
for model in available_models[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
    print(f"  - {model}")
```

### å¤šè¯´è¯äººæ¨¡å‹
```python
# ä½¿ç”¨å¤šè¯´è¯äººæ¨¡å‹
tts = CoquiTTS(model_name="tts_models/en/vctk/vits")

# è·å–å¯ç”¨è¯´è¯äºº
voices = tts.list_voices()
for voice in voices[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
    print(f"{voice.name}: {voice.display_name}")

# æŒ‡å®šè¯´è¯äººåˆæˆ
request = TTSRequest(
    text="This is a multi-speaker TTS model.",
    voice_name="p225",  # VCTKæ•°æ®é›†ä¸­çš„è¯´è¯äººID
    output_dir="./output"
)

response = tts.synthesize(request)
```

### è¯­éŸ³å…‹éš†
```python
# ä½¿ç”¨è¯­éŸ³å…‹éš†åŠŸèƒ½
tts = CoquiTTS(model_name="tts_models/multilingual/multi-dataset/your_tts")

# æ–¹æ³•1: é€šè¿‡TTSRequest
request = TTSRequest(
    text="This is voice cloning with Coqui TTS.",
    speaker_wav="path/to/reference_voice.wav",  # å‚è€ƒè¯­éŸ³æ–‡ä»¶
    language="en",
    output_dir="./output"
)

response = tts.synthesize(request)

# æ–¹æ³•2: ç›´æ¥è°ƒç”¨å…‹éš†æ–¹æ³•
cloned_audio = tts.clone_voice(
    text="Hello, this is my cloned voice!",
    speaker_wav="path/to/reference_voice.wav",
    output_path="./output/cloned_voice.wav",
    language="en"
)
```

### å¤šè¯­è¨€åˆæˆ
```python
# ä¸­æ–‡åˆæˆ
tts_zh = CoquiTTS(model_name="tts_models/zh-CN/baker/tacotron2-DDC-GST")

request = TTSRequest(
    text="ä½ å¥½ï¼Œè¿™æ˜¯Coqui TTSä¸­æ–‡è¯­éŸ³åˆæˆã€‚",
    output_dir="./output"
)

response = tts_zh.synthesize(request)

# è¥¿ç­ç‰™è¯­åˆæˆ
tts_es = CoquiTTS(model_name="tts_models/es/mai/tacotron2-DDC")

request = TTSRequest(
    text="Hola, esto es sÃ­ntesis de voz en espaÃ±ol.",
    output_dir="./output"
)

response = tts_es.synthesize(request)
```

### ç”Ÿæˆå­—å¹•
```python
# åŒæ—¶ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•
request = TTSRequest(
    text="This text will be converted to speech with subtitles.",
    voice_name="default",
    subtitle_format="srt,frt",  # ç”ŸæˆSRTå’ŒFRTæ ¼å¼å­—å¹•
    output_dir="./output"
)

response = tts.synthesize(request)
print(f"éŸ³é¢‘æ–‡ä»¶: {response.audio_file}")
print(f"SRTå­—å¹•: {response.subtitle_file}")
print(f"FRTå­—å¹•: {response.frt_subtitle_file}")
```

### æ‰¹é‡å¤„ç†
```python
texts = [
    "First sentence to synthesize.",
    "Second sentence for batch processing.",
    "Third and final sentence."
]

responses = []
for i, text in enumerate(texts):
    request = TTSRequest(
        text=text,
        voice_name="default",
        output_dir=f"./output/batch_{i}"
    )
    response = tts.synthesize(request)
    responses.append(response)

print(f"æ‰¹é‡å¤„ç†å®Œæˆï¼Œç”Ÿæˆäº† {len(responses)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
```

### é«˜çº§é…ç½®
```python
# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆå§‹åŒ–
tts = CoquiTTS(
    model_name="tts_models/en/ljspeech/vits",
    device="cuda",
    sample_rate=44100,
    language="en",
    emotion="happy"
)

# è·å–å¼•æ“ä¿¡æ¯
info = tts.get_engine_info()
print(f"å¼•æ“: {info['name']} v{info['version']}")
print(f"å½“å‰æ¨¡å‹: {info['model_name']}")
print(f"æ”¯æŒçš„è¯­è¨€: {info['supported_languages']}")
```

## å¯ç”¨æ¨¡å‹

### è‹±è¯­æ¨¡å‹
| æ¨¡å‹åç§° | æ¶æ„ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|----------|------|------|----------|
| tts_models/en/ljspeech/tacotron2-DDC | Tacotron2 | ç»å…¸æ¨¡å‹ï¼Œç¨³å®šå¯é  | é€šç”¨è‹±è¯­åˆæˆ |
| tts_models/en/ljspeech/vits | VITS | å¿«é€Ÿé«˜è´¨é‡ | å®æ—¶åº”ç”¨ |
| tts_models/en/vctk/vits | VITS | å¤šè¯´è¯äºº | éœ€è¦ä¸åŒå£°éŸ³ |
| tts_models/en/ljspeech/glow-tts | GlowTTS | å¹¶è¡Œç”Ÿæˆ | å¿«é€Ÿåˆæˆ |

### å¤šè¯­è¨€æ¨¡å‹
| æ¨¡å‹åç§° | æ”¯æŒè¯­è¨€ | ç‰¹ç‚¹ |
|----------|----------|------|
| tts_models/multilingual/multi-dataset/your_tts | 17ç§è¯­è¨€ | è¯­éŸ³å…‹éš† |
| tts_models/multilingual/multi-dataset/bark | å¤šè¯­è¨€ | æ”¯æŒéŸ³æ•ˆ |

### ä¸­æ–‡æ¨¡å‹
| æ¨¡å‹åç§° | ç‰¹ç‚¹ | æ•°æ®é›† |
|----------|------|--------|
| tts_models/zh-CN/baker/tacotron2-DDC-GST | æƒ…æ„Ÿæ§åˆ¶ | Bakeræ•°æ®é›† |

### è·å–å®Œæ•´æ¨¡å‹åˆ—è¡¨
```python
# è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
models = tts.list_available_models()

# æŒ‰è¯­è¨€ç­›é€‰
en_models = [m for m in models if '/en/' in m]
zh_models = [m for m in models if '/zh/' in m]

print(f"è‹±è¯­æ¨¡å‹æ•°é‡: {len(en_models)}")
print(f"ä¸­æ–‡æ¨¡å‹æ•°é‡: {len(zh_models)}")
```

## æ€§èƒ½ä¼˜åŒ–

### GPUåŠ é€Ÿ
```python
# ä½¿ç”¨GPUåŠ é€Ÿ
tts = CoquiTTS(
    model_name="tts_models/en/ljspeech/vits",
    device="cuda"
)

# æ£€æŸ¥GPUçŠ¶æ€
import torch
if torch.cuda.is_available():
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
```

### æ¨¡å‹é€‰æ‹©å»ºè®®
```python
# å®æ—¶åº”ç”¨ - é€‰æ‹©VITSæ¨¡å‹
tts_realtime = CoquiTTS(model_name="tts_models/en/ljspeech/vits")

# é«˜è´¨é‡åº”ç”¨ - é€‰æ‹©Tacotron2æ¨¡å‹
tts_quality = CoquiTTS(model_name="tts_models/en/ljspeech/tacotron2-DDC")

# è¯­éŸ³å…‹éš† - é€‰æ‹©YourTTSæ¨¡å‹
tts_clone = CoquiTTS(model_name="tts_models/multilingual/multi-dataset/your_tts")
```

### å†…å­˜ä¼˜åŒ–
```python
# å¯¹äºå†…å­˜å—é™çš„ç¯å¢ƒ
tts = CoquiTTS(
    model_name="tts_models/en/ljspeech/speedy-speech",  # è½»é‡çº§æ¨¡å‹
    device="cpu"
)
```

## é™åˆ¶è¯´æ˜

### æ–‡æœ¬é•¿åº¦
- **å•æ¬¡åˆæˆ**: å»ºè®®ä¸è¶…è¿‡500ä¸ªå•è¯
- **é•¿æ–‡æœ¬**: å»ºè®®åˆ†æ®µå¤„ç†ååˆå¹¶

### ç¡¬ä»¶è¦æ±‚
- **æœ€ä½é…ç½®**: 4GB RAM, CPU
- **æ¨èé…ç½®**: 8GB+ RAM, GPU (6GB+ VRAM)
- **GPUæ”¯æŒ**: NVIDIA GPU with CUDA 11.0+

### æ¨¡å‹é™åˆ¶
- æŸäº›æ¨¡å‹ä»…æ”¯æŒç‰¹å®šè¯­è¨€
- è¯­éŸ³å…‹éš†éœ€è¦å¤šè¯­è¨€æ¨¡å‹
- æƒ…æ„Ÿæ§åˆ¶ä»…éƒ¨åˆ†æ¨¡å‹æ”¯æŒ

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
é”™è¯¯: æ— æ³•ä¸‹è½½æ¨¡å‹
è§£å†³: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°ç¼“å­˜ç›®å½•
```

#### 2. GPUå†…å­˜ä¸è¶³
```bash
é”™è¯¯: CUDA out of memory
è§£å†³: ä½¿ç”¨CPUæ¨¡å¼æˆ–é€‰æ‹©æ›´å°çš„æ¨¡å‹
```

#### 3. éŸ³é¢‘è´¨é‡é—®é¢˜
```bash
é—®é¢˜: åˆæˆéŸ³é¢‘æœ‰æ‚éŸ³
è§£å†³: å°è¯•ä¸åŒçš„æ¨¡å‹æˆ–è°ƒæ•´é‡‡æ ·ç‡
```

#### 4. è¯­éŸ³å…‹éš†æ•ˆæœå·®
```bash
é—®é¢˜: å…‹éš†çš„å£°éŸ³ä¸åƒå‚è€ƒéŸ³é¢‘
è§£å†³: ç¡®ä¿å‚è€ƒéŸ³é¢‘è´¨é‡å¥½ï¼Œæ—¶é•¿3-10ç§’ï¼Œä½¿ç”¨YourTTSæ¨¡å‹
```

### è°ƒè¯•æ¨¡å¼
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# å¯ç”¨è¯¦ç»†æ—¥å¿—
tts = CoquiTTS(model_name="tts_models/en/ljspeech/vits")
```

### æ€§èƒ½ç›‘æ§
```python
import time

start_time = time.time()
response = tts.synthesize(request)
synthesis_time = time.time() - start_time

print(f"åˆæˆè€—æ—¶: {synthesis_time:.2f}ç§’")
print(f"éŸ³é¢‘æ—¶é•¿: {response.duration:.2f}ç§’")
print(f"å®æ—¶ç‡: {response.duration/synthesis_time:.2f}x")
```

## æœ€ä½³å®è·µ

### 1. æ¨¡å‹é€‰æ‹©
```python
# æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹
def choose_model(use_case):
    if use_case == "realtime":
        return "tts_models/en/ljspeech/vits"
    elif use_case == "quality":
        return "tts_models/en/ljspeech/tacotron2-DDC"
    elif use_case == "multilingual":
        return "tts_models/multilingual/multi-dataset/your_tts"
    elif use_case == "voice_cloning":
        return "tts_models/multilingual/multi-dataset/your_tts"
    else:
        return "tts_models/en/ljspeech/vits"

model_name = choose_model("realtime")
tts = CoquiTTS(model_name=model_name)
```

### 2. æ–‡æœ¬é¢„å¤„ç†
```python
import re

def preprocess_text(text):
    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[^\w\s.,!?;:]', '', text)
    # å¤„ç†æ•°å­—
    text = re.sub(r'\d+', lambda m: num2words(int(m.group())), text)
    # è§„èŒƒåŒ–ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text.strip())
    return text

request = TTSRequest(
    text=preprocess_text("åŸå§‹æ–‡æœ¬..."),
    voice_name="default"
)
```

### 3. é”™è¯¯å¤„ç†
```python
def safe_synthesize(tts, request, max_retries=3):
    for attempt in range(max_retries):
        try:
            return tts.synthesize(request)
        except RuntimeError as e:
            if attempt == max_retries - 1:
                raise
            print(f"åˆæˆå¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")
            time.sleep(1)

# ä½¿ç”¨æ–¹å¼
try:
    response = safe_synthesize(tts, request)
except Exception as e:
    print(f"æœ€ç»ˆåˆæˆå¤±è´¥: {e}")
```

### 4. èµ„æºç®¡ç†
```python
class TTSManager:
    def __init__(self, model_name):
        self.model_name = model_name
        self.tts = None
    
    def __enter__(self):
        self.tts = CoquiTTS(model_name=self.model_name)
        return self.tts
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        # æ¸…ç†èµ„æº
        if self.tts and hasattr(self.tts, 'tts_model'):
            del self.tts.tts_model
        del self.tts

# ä½¿ç”¨æ–¹å¼
with TTSManager("tts_models/en/ljspeech/vits") as tts:
    response = tts.synthesize(request)
```

## ç‰ˆæœ¬å†å²

### v0.22.0 (å½“å‰ç‰ˆæœ¬)
- æ”¯æŒæœ€æ–°çš„VITSå’ŒYourTTSæ¨¡å‹
- æ”¹è¿›çš„è¯­éŸ³å…‹éš†åŠŸèƒ½
- ä¼˜åŒ–çš„æ¨ç†æ€§èƒ½
- æ‰©å±•çš„å¤šè¯­è¨€æ”¯æŒ

### v0.21.0
- æ·»åŠ Barkæ¨¡å‹æ”¯æŒ
- æ”¹è¿›çš„æƒ…æ„Ÿæ§åˆ¶
- æ–°çš„å¤šè¯­è¨€æ¨¡å‹

### v0.20.0
- é‡æ„çš„APIæ¥å£
- æ”¹è¿›çš„æ¨¡å‹ç®¡ç†
- æ€§èƒ½ä¼˜åŒ–

## ç›¸å…³é“¾æ¥

### å®˜æ–¹èµ„æº
- **GitHubä»“åº“**: [https://github.com/coqui-ai/TTS](https://github.com/coqui-ai/TTS)
- **å®˜æ–¹æ–‡æ¡£**: [https://tts.readthedocs.io/](https://tts.readthedocs.io/)
- **PyPIé¡µé¢**: [https://pypi.org/project/TTS/](https://pypi.org/project/TTS/)
- **æ¨¡å‹åˆ—è¡¨**: [https://github.com/coqui-ai/TTS/blob/dev/TTS/.models.json](https://github.com/coqui-ai/TTS/blob/dev/TTS/.models.json)

### æŠ€æœ¯æ–‡æ¡£
- **è®ºæ–‡é›†åˆ**: [Coqui TTS Papers](https://github.com/coqui-ai/TTS#papers)
- **æ¨¡å‹æ¶æ„**: [TTS Models](https://tts.readthedocs.io/en/latest/models/)
- **è®­ç»ƒæŒ‡å—**: [Training Guide](https://tts.readthedocs.io/en/latest/tutorial_for_nervous_beginners.html)

### ç¤¾åŒºèµ„æº
- **è®¨è®ºåŒº**: [GitHub Discussions](https://github.com/coqui-ai/TTS/discussions)
- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/coqui-ai/TTS/issues)
- **Discordç¤¾åŒº**: [Coqui Discord](https://discord.gg/5eXr5seRrv)

### ç›¸å…³é¡¹ç›®
- **Coqui STT**: [https://github.com/coqui-ai/STT](https://github.com/coqui-ai/STT)
- **Mozilla DeepSpeech**: [https://github.com/mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)

### é¢„è®­ç»ƒæ¨¡å‹
- **Hugging Face Models**: [https://huggingface.co/coqui](https://huggingface.co/coqui)
- **æ¨¡å‹ä¸‹è½½**: æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° `~/.local/share/tts/`

---

å¦‚éœ€æ›´å¤šå¸®åŠ©ï¼Œè¯·å‚è€ƒ [FunTTSä¸»æ–‡æ¡£](../../README.md) æˆ–è®¿é—® [Coqui TTSå®˜æ–¹ä»“åº“](https://github.com/coqui-ai/TTS)ã€‚
